---
title: "Introduction to frbayes"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{introduction_to_frbayes}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(frbayes)
library(ggplot2)
library(purrr)
library(dplyr)
library(tidyr)
```


In this vignette, we provide an introduction to `frbayes`, a package for fitting
to functional response data.

## Synthetic study
We first show how we can fit a functional response model to synthetically generated
data, where the parameters of the process are known. We assume that data generating
process is a stochastic Rogers-II-type model, where the process is assumed to
follow a chemical reaction equation of the form:

$$
\text{prey} \xrightarrow{\text{rate}} \text{prey} - 1,
$$

where the rate of this reaction is given by:

$$
\text{rate} = \frac{a \cdot \text{prey}}{1 + a \cdot h \cdot \text{prey}},
$$

where $a$ is a capture rate and $h$ is a handling time. Here, we assume in our
synthetic data that $a=2$ and $h=0.1$.

We suppose that 100 replicates were performed at initial prey counts of: 5,
10, 20, 30, 40, and we generate a possible observed dataset for this experimental
setup.
```{r}
# experiment details
experimental_setup <- data.frame(
  n_prey_initial = c(5, 10, 20, 30, 40),
  n_replicates = 100
)

# generate synthetic data
true_parameters <- list(a=2, h=0.1)
df <- simulate_study(
  data=experimental_setup,
  time_max = 1,
  model = model_rogersII(),
  parameters = true_parameters
)

# plot data
df %>% 
  ggplot(aes(x=n_prey_initial, y=n_prey_eaten)) +
  geom_jitter(height = 0.3)
```

We now fit a model to these data using maximum likelihood estimation. To do so, we use the `log_probability` function. We first show how the log-likelihood varies as $a$ is varied with $h$ fixed at its true value.
```{r}
as <- seq(1, 4, 0.1)
log_likelihood <- vector(length = length(as))

for(i in seq_along(as)) {
  parameters <- list(a = as[i], h = true_parameters$h)
  log_likelihood[i] <- log_probability(
    parameters = parameters,
    data = df,
    model = model_rogersII(),
    n_replicates = 10000)
}

# plot
tibble(a=as, log_likelihood=log_likelihood) %>% 
  ggplot(aes(x=a, y=log_likelihood)) +
  geom_line() +
  geom_vline(xintercept = true_parameters$a, linetype=2)
```

Similarly so, for $h$.
```{r}
hs <- seq(0.01, 0.25, 0.01)
log_likelihood <- vector(length = length(hs))

for(i in seq_along(hs)) {
  parameters <- list(a = true_parameters$a, h=hs[i])
  log_likelihood[i] <- log_probability(
    parameters = parameters,
    data = df,
    model = model_rogersII(),
    n_replicates = 1000)
}

# plot
tibble(h=hs, log_likelihood=log_likelihood) %>% 
  ggplot(aes(x=h, y=log_likelihood)) +
  geom_line() +
  geom_vline(xintercept = true_parameters$h, linetype=2)
```

We can also look at the 2D likelihood surface. Here, we mark the true parameter set as a point.
```{r}
parameter_combinations <- expand_grid(a=as, h=hs)
parameter_combinations$z <- NA
for(i in seq_along(parameter_combinations$a)) {
  parameters <- list(a = parameter_combinations$a[i],
                     h = parameter_combinations$h[i])
  z <- log_probability(
    parameters = parameters,
    data = df,
    model = model_rogersII(),
    n_replicates = 1000) # smaller sample
  parameter_combinations$z[i] <- z
}

# plot
ggplot(parameter_combinations, aes(x = a, y = h, fill = z)) +
  geom_raster() +
  scale_fill_viridis_c() +  # Using continuous viridis color scale
  theme_minimal() +
  geom_point(data=data.frame(h=true_parameters$h, a=true_parameters$a)) +
  geom_contour(aes(z = z), color = "white")
```


We now perform optimisation to estimate $(a,h)$.
```{r}
# set a function to minimise
f_likelihood <- function(theta) {
  parameters <- list(a=1.5, h=0.1) #  these are dummy values
  parameters[1] <- theta[1]
  parameters[2] <- theta[2]
  -log_probability( # minus sign needed as optim minimises
    parameters = parameters,
    data = df,
    model = model_rogersII(),
    n_replicates = 10000)
}

# use R's standard optim
fit <- optim(
  c(1.5, 0.1),
  f_likelihood,
  lower=c(0.01, 0.01),
  upper=c(5, 0.25)
)

# output pars
a <- fit$par[1]
h <- fit$par[2]
mle_parameters <- list(a=a, h=h)
print(paste0("a = ", a, ", h = ", h))
```

We then mark the MLE values as a cross on the 2D likelihood surface.
```{r}
# overlay on 2D plot
ggplot(parameter_combinations, aes(x = a, y = h, fill = z)) +
  geom_raster() +
  scale_fill_viridis_c() +  # Using continuous viridis color scale
  theme_minimal() +
  geom_point(data=data.frame(h=true_parameters$h, a=true_parameters$a)) +
  geom_point(data=data.frame(h=h, a=a), shape=4, size=4) +
  geom_contour(aes(z = z), color = "white")
```


We now examine the fit of the model to data.
```{r}
experimental_setup <- data.frame(
  n_prey_initial = c(5, 10, 20, 30, 40),
  n_replicates = 1000
)

# generate synthetic data at max likelihood estimates
df_sim <- simulate_study(
  data=experimental_setup,
  time_max = 1,
  model = model_rogersII(),
  parameters = mle_parameters
)

# plot
df %>%
  ggplot(aes(x=as.factor(n_prey_initial), y=n_prey_eaten)) +
  geom_violin(data=df_sim) +
  geom_jitter(height = 0.3) +
  xlab("n_prey_initial")
```
We can also plot the empirical cumulative distribution function (eCDF) versus the model-simulated eCDFs. Here, we plot these for each value of `n_prey_initial` across 100 bootstrapped samples. The model fit isn't perfect perhaps owing to the difficulty of maximising the likelihood here.
```{r}
# generate ecdfs
n_bootstraps <- 100
df_ecdfs_both <- create_bootstrapped_ecdf_real_simulated(
    n_bootstraps = n_bootstraps,
    data = df,
    time_max = 1,
    model = model_rogersII(),
    mle_parameters = mle_parameters
)

# plot
df_ecdfs_both %>% 
  ggplot(aes(x=ecdf_real, y=ecdf_sim, group=as.factor(bootstrap_id))) +
  geom_line(alpha=0.5) +
  facet_wrap(~n_prey_initial) +
  geom_abline(linetype=2, colour="orange")
```

As a sanity check, we repeat these checks using the true parameter values. This shows a reasonable fit.
```{r}
# generate ecdfs
n_bootstraps <- 100
df_ecdfs_both <- create_bootstrapped_ecdf_real_simulated(
    n_bootstraps = n_bootstraps,
    data = df,
    time_max = 1,
    model = model_rogersII(),
    mle_parameters = true_parameters
)

# plot
df_ecdfs_both %>% 
  ggplot(aes(x=ecdf_real, y=ecdf_sim, group=as.factor(bootstrap_id))) +
  geom_line(alpha=0.5) +
  facet_wrap(~n_prey_initial) +
  geom_abline(linetype=2, colour="orange")
```

